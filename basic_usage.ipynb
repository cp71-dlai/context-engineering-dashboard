{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context Engineering Dashboard â€” Basic Usage\n",
    "\n",
    "This notebook demonstrates how to visualize LLM context windows using the `context-engineering-dashboard` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install (if needed)\n",
    "# !pip install context-engineering-dashboard[all]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Manual Trace Construction\n",
    "\n",
    "Build a trace manually to understand the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from context_engineering_dashboard import (\n",
    "    ContextTrace,\n",
    "    ContextComponent,\n",
    "    ComponentType,\n",
    "    ContextWindow,\n",
    ")\n",
    "\n",
    "# Create components manually\n",
    "components = [\n",
    "    ContextComponent(\n",
    "        id=\"sys_1\",\n",
    "        type=ComponentType.SYSTEM_PROMPT,\n",
    "        content=\"You are a helpful assistant specializing in ChromaDB documentation.\",\n",
    "        token_count=2000,\n",
    "    ),\n",
    "    ContextComponent(\n",
    "        id=\"rag_1\",\n",
    "        type=ComponentType.RAG_DOCUMENT,\n",
    "        content=\"# Getting Started with ChromaDB\\n\\nChromaDB is an open-source embedding database...\",\n",
    "        token_count=8000,\n",
    "        metadata={\"chroma_score\": 0.92, \"source\": \"docs/getting-started.md\"},\n",
    "    ),\n",
    "    ContextComponent(\n",
    "        id=\"rag_2\",\n",
    "        type=ComponentType.RAG_DOCUMENT,\n",
    "        content=\"# Collections\\n\\nA collection is the main container for documents...\",\n",
    "        token_count=3000,\n",
    "        metadata={\"chroma_score\": 0.87, \"source\": \"docs/collections.md\"},\n",
    "    ),\n",
    "    ContextComponent(\n",
    "        id=\"history_1\",\n",
    "        type=ComponentType.CHAT_HISTORY,\n",
    "        content=\"Previous turn: User asked about installation...\",\n",
    "        token_count=1000,\n",
    "    ),\n",
    "    ContextComponent(\n",
    "        id=\"user_1\",\n",
    "        type=ComponentType.USER_MESSAGE,\n",
    "        content=\"How do I create a collection in Chroma?\",\n",
    "        token_count=350,\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Create trace\n",
    "trace = ContextTrace(\n",
    "    context_limit=128_000,\n",
    "    components=components,\n",
    "    total_tokens=sum(c.token_count for c in components),\n",
    ")\n",
    "\n",
    "print(f\"Total tokens: {trace.total_tokens:,}\")\n",
    "print(f\"Utilization: {trace.utilization:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualize with ContextWindow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIEW mode (default)\n",
    "ctx = ContextWindow(trace=trace, context_limit=128_000)\n",
    "ctx.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPLORE mode (double-click components to see details)\n",
    "ctx = ContextWindow(trace=trace, context_limit=128_000, mode=\"explore\")\n",
    "ctx.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Trace with OpenAI\n",
    "\n",
    "Automatically capture context from OpenAI calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from context_engineering_dashboard import trace_openai\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "with trace_openai() as tracer:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful coding assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Explain what context engineering is in 2 sentences.\"},\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "    )\n",
    "\n",
    "# Visualize\n",
    "ctx = ContextWindow(trace=tracer.result)\n",
    "ctx.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Trace with Chroma RAG\n",
    "\n",
    "Full RAG workflow with Chroma retrieval tracing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from context_engineering_dashboard import trace_chroma, ContextWindow\n",
    "\n",
    "# Setup Chroma\n",
    "chroma_client = chromadb.Client()\n",
    "collection = chroma_client.get_or_create_collection(\"docs\")\n",
    "\n",
    "# Add some documents\n",
    "collection.add(\n",
    "    ids=[\"doc_1\", \"doc_2\", \"doc_3\", \"doc_4\", \"doc_5\"],\n",
    "    documents=[\n",
    "        \"ChromaDB is an open-source embedding database designed for AI applications.\",\n",
    "        \"To create a collection, use client.create_collection('name').\",\n",
    "        \"Embeddings can be generated using OpenAI, Cohere, or local models.\",\n",
    "        \"The query method returns the most similar documents based on cosine similarity.\",\n",
    "        \"Metadata filtering allows you to narrow down results using key-value pairs.\",\n",
    "    ],\n",
    "    metadatas=[\n",
    "        {\"source\": \"overview.md\"},\n",
    "        {\"source\": \"collections.md\"},\n",
    "        {\"source\": \"embeddings.md\"},\n",
    "        {\"source\": \"querying.md\"},\n",
    "        {\"source\": \"filtering.md\"},\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap collection for tracing\n",
    "traced = trace_chroma(collection)\n",
    "\n",
    "# Query (captures all returned docs)\n",
    "results = traced.query(\n",
    "    query_texts=[\"How do I create a collection?\"],\n",
    "    n_results=5,\n",
    ")\n",
    "\n",
    "# Mark which docs we select for context (e.g., top 2)\n",
    "traced.mark_selected([\"doc_2\", \"doc_1\"])\n",
    "\n",
    "# Add other context components\n",
    "traced.add_system_prompt(\"You are a helpful assistant for ChromaDB.\")\n",
    "traced.add_user_message(\"How do I create a collection?\")\n",
    "\n",
    "# Get trace and visualize\n",
    "trace = traced.get_trace(context_limit=128_000)\n",
    "ctx = ContextWindow(trace=trace, mode=\"explore\", show_available_pool=True)\n",
    "ctx.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Serialization\n",
    "\n",
    "Save and load traces for later analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to JSON\n",
    "trace.to_json(\"my_trace.json\")\n",
    "\n",
    "# Load from JSON\n",
    "loaded_trace = ContextTrace.from_json(\"my_trace.json\")\n",
    "\n",
    "# Verify\n",
    "print(f\"Components: {len(loaded_trace.components)}\")\n",
    "print(f\"Total tokens: {loaded_trace.total_tokens:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare Before/After with Sankey Diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from context_engineering_dashboard import ContextDiff\n",
    "\n",
    "# Create a \"before\" trace with more content\n",
    "before_components = [\n",
    "    ContextComponent(id=\"sys\", type=ComponentType.SYSTEM_PROMPT, content=\"...\", token_count=4000),\n",
    "    ContextComponent(id=\"hist\", type=ComponentType.CHAT_HISTORY, content=\"...\", token_count=20000),\n",
    "    ContextComponent(id=\"rag\", type=ComponentType.RAG_DOCUMENT, content=\"...\", token_count=15000),\n",
    "    ContextComponent(id=\"tool\", type=ComponentType.TOOL, content=\"...\", token_count=1000),\n",
    "]\n",
    "before = ContextTrace(\n",
    "    context_limit=128_000,\n",
    "    components=before_components,\n",
    "    total_tokens=40000,\n",
    ")\n",
    "\n",
    "# Create an \"after\" trace (compacted)\n",
    "after_components = [\n",
    "    ContextComponent(id=\"sys\", type=ComponentType.SYSTEM_PROMPT, content=\"...\", token_count=4000),\n",
    "    ContextComponent(id=\"hist\", type=ComponentType.CHAT_HISTORY, content=\"...\", token_count=8000),\n",
    "    ContextComponent(id=\"rag\", type=ComponentType.RAG_DOCUMENT, content=\"...\", token_count=10000),\n",
    "    ContextComponent(id=\"tool\", type=ComponentType.TOOL, content=\"...\", token_count=1000),\n",
    "]\n",
    "after = ContextTrace(\n",
    "    context_limit=128_000,\n",
    "    components=after_components,\n",
    "    total_tokens=23000,\n",
    ")\n",
    "\n",
    "# Visualize diff\n",
    "diff = ContextDiff(\n",
    "    before=before,\n",
    "    after=after,\n",
    "    before_label=\"Original\",\n",
    "    after_label=\"After /compact\",\n",
    ")\n",
    "diff.sankey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print text summary\n",
    "diff.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
